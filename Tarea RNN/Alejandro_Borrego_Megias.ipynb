{"cells":[{"cell_type":"markdown","id":"prospective-america","metadata":{"id":"prospective-america"},"source":["Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n","\n","Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n","\n","**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"]},{"cell_type":"markdown","id":"novel-stewart","metadata":{"id":"novel-stewart"},"source":["El examen se divide en tres partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n","\n","    \n","- [Actividad 1: Redes Recurrentes](#actividad_1): 10 pts\n","    - [Cuestión 1](#3.1): 2.5 pt\n","    - [Cuestión 2](#3.2): 2.5 pt\n","    - [Cuestión 3](#3.3): 2.5 pts\n","    - [Cuestión 4](#3.4): 1.25 pts\n","    - [Cuestión 5](#3.5): 1.25 pts\n","\n"]},{"cell_type":"code","execution_count":92,"id":"prompt-developer","metadata":{"id":"prompt-developer"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import random"]},{"cell_type":"markdown","id":"regional-favorite","metadata":{"id":"regional-favorite"},"source":["<a name='actividad_1'></a>\n","# Actividad 1: Redes Recurrentes\n","\n","\n","- [Cuestión 1](#3.1): 2.5 pt\n","- [Cuestión 2](#3.2): 2.5 pt\n","- [Cuestión 3](#3.3): 2.5 pts\n","- [Cuestión 4](#3.4): 1.25 pts\n","- [Cuestión 5](#3.5): 1.25 pts\n","\n","Vamos a usar un dataset de las temperaturas mínimas diarias en Melbourne. La tarea será la de predecir la temperatura mínima en dos días. Puedes usar técnicas de series temporales vistas en otras asignaturas, pero no es necesario.\n"]},{"cell_type":"code","execution_count":93,"id":"empty-value","metadata":{"id":"empty-value"},"outputs":[],"source":["dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n","data_dir = tf.keras.utils.get_file('daily-min-temperatures.csv', origin=dataset_url)"]},{"cell_type":"code","execution_count":94,"id":"numerous-situation","metadata":{"id":"numerous-situation"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Temp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1981-01-01</td>\n","      <td>20.7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1981-01-02</td>\n","      <td>17.9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1981-01-03</td>\n","      <td>18.8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1981-01-04</td>\n","      <td>14.6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1981-01-05</td>\n","      <td>15.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Date  Temp\n","0 1981-01-01  20.7\n","1 1981-01-02  17.9\n","2 1981-01-03  18.8\n","3 1981-01-04  14.6\n","4 1981-01-05  15.8"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(data_dir, parse_dates=['Date'])\n","df.head()"]},{"cell_type":"code","execution_count":95,"id":"copyrighted-madonna","metadata":{"id":"copyrighted-madonna"},"outputs":[{"name":"stdout","output_type":"stream","text":["number of samples: 3650\n","number of train samples: 3000\n","number of test samples: 650\n","firsts trainn samples: [20.7 17.9 18.8 14.6 15.8 15.8 15.8 17.4 21.8 20. ]\n"]}],"source":["temperatures = df['Temp'].values\n","print('number of samples:', len(temperatures))\n","train_data = temperatures[:3000]\n","test_data = temperatures[3000:]\n","print('number of train samples:', len(train_data))\n","print('number of test samples:', len(test_data))\n","print('firsts trainn samples:', train_data[:10])"]},{"cell_type":"markdown","id":"adapted-brief","metadata":{"id":"adapted-brief"},"source":["<a name='3.1'></a>\n","## Cuestión 1: Convierta `train_data` y `test_data`  en ventanas de tamaño 5, para predecir el valor en 2 días\n","\n","En la nomenclatura de [Introduction_to_RNN_Time_Series.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n","```python\n","past, future = (5, 2)\n","```\n","\n","Para las primeras 10 muestras de train_data `[20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ]` el resultado debería ser:\n","\n","```python\n","x[0] : [20.7, 17.9, 18.8, 14.6, 15.8] , y[0]: 15.8\n","x[1] : [17.9, 18.8, 14.6, 15.8, 15.8] , y[1]: 17.4\n","x[2] : [18.8, 14.6, 15.8, 15.8, 15.8] , y[2]: 21.8\n","x[3] : [14.6, 15.8, 15.8, 15.8, 17.4] , y[3]: 20.             \n","```"]},{"cell_type":"code","execution_count":96,"id":"7bf1f394","metadata":{},"outputs":[],"source":["seed_value = 42\n","np.random.seed(seed_value)\n","tf.random.set_seed(seed_value)\n","random.seed(seed_value)"]},{"cell_type":"code","execution_count":97,"id":"conscious-teaching","metadata":{"id":"conscious-teaching"},"outputs":[],"source":["# windowing function\n","def create_windows_np(data, window_size, horizon, shuffle=False):\n","    \"\"\"\n","    Creates a dataset from the given time series data using NumPy.\n","    \n","    Parameters:\n","    data (np.ndarray): Time series data with one dimension.\n","    window_size (int): The number of past time steps to use as input features.\n","    horizon (int): The number of future time steps to predict.\n","    shuffle (bool): Shuffle the windows or not.\n","    \n","    Returns:\n","    tuple: A tuple containing the input-output pairs (windows, targets) as NumPy arrays.\n","    \"\"\"\n","\n","    X, y = [], []\n","    for i in range(len(data) - window_size - horizon + 1):\n","        X.append(data[i:i+window_size])\n","        y.append(data[i+window_size+horizon-1])\n","\n","    X, y = np.array(X), np.array(y)\n","    \n","    if shuffle:\n","        indices = np.arange(len(X))\n","        np.random.shuffle(indices)\n","        X, y = X[indices], y[indices]\n","    \n","    return X, y"]},{"cell_type":"code","execution_count":98,"id":"joint-annotation","metadata":{"id":"joint-annotation"},"outputs":[],"source":["past, future = (5, 2)\n","X_train, y_train = create_windows_np(train_data, past, future)\n","X_test, y_test = create_windows_np(test_data, past, future)"]},{"cell_type":"code","execution_count":99,"id":"288af801","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["x[0]: [20.7 17.9 18.8 14.6 15.8],  y[0]: 15.8\n","x[1]: [17.9 18.8 14.6 15.8 15.8],  y[1]: 17.4\n","x[2]: [18.8 14.6 15.8 15.8 15.8],  y[2]: 21.8\n","x[3]: [14.6 15.8 15.8 15.8 17.4],  y[3]: 20.0\n","x[4]: [15.8 15.8 15.8 17.4 21.8],  y[4]: 16.2\n","x[5]: [15.8 15.8 17.4 21.8 20. ],  y[5]: 13.3\n","x[6]: [15.8 17.4 21.8 20.  16.2],  y[6]: 16.7\n","x[7]: [17.4 21.8 20.  16.2 13.3],  y[7]: 21.5\n","x[8]: [21.8 20.  16.2 13.3 16.7],  y[8]: 25.0\n","x[9]: [20.  16.2 13.3 16.7 21.5],  y[9]: 20.7\n"]}],"source":["for i in range(10):\n","    print(f\"x[{i}]: {X_train[i]},  y[{i}]: {y_train[i]}\")"]},{"cell_type":"markdown","id":"electrical-junior","metadata":{"id":"electrical-junior"},"source":["<a name='3.2'></a>\n","## Cuestión 2: Cree un modelo recurrente de dos capas GRU para predecir con las ventanas de la cuestión anterior.\n"]},{"cell_type":"code","execution_count":100,"id":"aboriginal-complaint","metadata":{"id":"aboriginal-complaint"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_25\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,864</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_8 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m12,864\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ gru_9 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,960\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,889</span> (148.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,889\u001b[0m (148.00 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,889</span> (148.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,889\u001b[0m (148.00 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["inputs = keras.layers.Input(shape=(5, 1))\n","# Añadir las capas GRU. Dado que queremos apilar GRU, necesitamos que la primera devuelva secuencias\n","x = keras.layers.GRU(64, return_sequences=True)(inputs)\n","x = keras.layers.GRU(64)(x)\n","\n","# Añadir una capa densa para la salida, queremos predecir un solo valor\n","outputs = keras.layers.Dense(1)(x)\n","\n","# Crear y compilar el modelo\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer='adam', loss='mse')\n","model.summary()"]},{"cell_type":"code","execution_count":101,"id":"applicable-longer","metadata":{"id":"applicable-longer"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 73.0039 - val_loss: 20.8326\n","Epoch 2/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16.4951 - val_loss: 18.1716\n","Epoch 3/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14.9107 - val_loss: 15.6878\n","Epoch 4/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 12.3114 - val_loss: 12.2268\n","Epoch 5/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 10.5327 - val_loss: 10.2985\n","Epoch 6/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.6520 - val_loss: 9.5350\n","Epoch 7/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.2589 - val_loss: 9.1977\n","Epoch 8/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.1023 - val_loss: 9.0360\n","Epoch 9/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.0315 - val_loss: 8.9282\n","Epoch 10/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.9845 - val_loss: 8.8427\n","Epoch 11/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9492 - val_loss: 8.7756\n","Epoch 12/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9225 - val_loss: 8.7212\n","Epoch 13/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9009 - val_loss: 8.6763\n","Epoch 14/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.8830 - val_loss: 8.6386\n","Epoch 15/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8679 - val_loss: 8.6064\n","Epoch 16/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8546 - val_loss: 8.5787\n","Epoch 17/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.8427 - val_loss: 8.5547\n","Epoch 18/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.8316 - val_loss: 8.5336\n","Epoch 19/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8212 - val_loss: 8.5150\n","Epoch 20/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.8113 - val_loss: 8.4984\n","Epoch 21/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 8.8018 - val_loss: 8.4834\n","Epoch 22/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 8.7926 - val_loss: 8.4698\n","Epoch 23/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 8.7837 - val_loss: 8.4574\n","Epoch 24/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.7751 - val_loss: 8.4460\n","Epoch 25/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7668 - val_loss: 8.4356\n","Epoch 26/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7587 - val_loss: 8.4261\n","Epoch 27/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.7506 - val_loss: 8.4174\n","Epoch 28/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7426 - val_loss: 8.4097\n","Epoch 29/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7345 - val_loss: 8.4029\n","Epoch 30/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.7264 - val_loss: 8.3972\n","Epoch 31/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7182 - val_loss: 8.3926\n","Epoch 32/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.7099 - val_loss: 8.3893\n","Epoch 33/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.7016 - val_loss: 8.3874\n","Epoch 34/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6934 - val_loss: 8.3869\n","Epoch 35/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6852 - val_loss: 8.3876\n","Epoch 36/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6772 - val_loss: 8.3893\n","Epoch 37/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6694 - val_loss: 8.3916\n","Epoch 38/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6616 - val_loss: 8.3941\n","Epoch 39/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6538 - val_loss: 8.3963\n","Epoch 40/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6459 - val_loss: 8.3979\n","Epoch 41/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.6378 - val_loss: 8.3987\n","Epoch 42/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.6297 - val_loss: 8.3980\n","Epoch 43/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.6215 - val_loss: 8.3957\n","Epoch 44/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.6129 - val_loss: 8.3922\n"]}],"source":["es_callback = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", min_delta=0, patience=10)\n","\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=200,\n","    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",")"]},{"cell_type":"code","execution_count":102,"id":"stone-province","metadata":{"id":"stone-province"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.8167\n","Test Loss: 6.737891674041748\n"]}],"source":["results = model.evaluate(X_test, y_test, verbose=1)\n","print('Test Loss: {}'.format(results))"]},{"cell_type":"markdown","id":"genetic-guitar","metadata":{"id":"genetic-guitar"},"source":["<a name='3.3'></a>\n","## Cuestión 3: Añada más features a la series temporal, por ejemplo `portion_year`. Cree un modelo que mejore al anterior.\n"]},{"cell_type":"code","execution_count":103,"id":"prospective-master","metadata":{"id":"prospective-master"},"outputs":[],"source":["## Puede añadir más features\n","df['portion_year'] = df['Date'].dt.dayofyear / 365.0\n","df['day_of_week'] = df['Date'].dt.dayofweek / 6.0  # Normalized\n","df['month_of_year'] = df['Date'].dt.month / 12.0  # Normalized\n","\n","df_multi = df[['Temp', 'portion_year', 'day_of_week', 'month_of_year']].copy()\n","\n","## train - test split\n","train_data = df_multi.iloc[:3000].copy()\n","test_data = df_multi.loc[3000:, :].copy()\n"]},{"cell_type":"code","execution_count":104,"id":"685474b2","metadata":{},"outputs":[],"source":["def create_windows_multivariate_np(data, window_size, horizon, target_col_idx, shuffle=False):\n","    \"\"\"\n","    Creates a dataset from the given time series data using NumPy.\n","\n","    Parameters:\n","    data (np.ndarray or pd.DataFrame): Time series data with multiple features.\n","    window_size (int): The number of past time steps to use as input features.\n","    horizon (int): The number of future time steps to predict.\n","    target_col_idx (int): The index of the target column in the input data.\n","    shuffle (bool): Whether to shuffle the data or not.\n","\n","    Returns:\n","    tuple: A tuple containing the input-output pairs (X, y) as NumPy arrays.\n","    \"\"\"\n","    if isinstance(data, pd.DataFrame):\n","        data = data.values\n","\n","    X, y = [], []\n","    for i in range(len(data) - window_size - horizon + 1):\n","        X.append(data[i:i+window_size, :])\n","        y.append(data[i+window_size+horizon-1, target_col_idx])\n","\n","    X, y = np.array(X), np.array(y)\n","\n","    if shuffle:\n","        indices = np.arange(X.shape[0])\n","        np.random.shuffle(indices)\n","        X, y = X[indices], y[indices]\n","\n","    return X, y"]},{"cell_type":"code","execution_count":105,"id":"threaded-sheriff","metadata":{"id":"threaded-sheriff"},"outputs":[{"name":"stdout","output_type":"stream","text":["x[0]: [[2.07000000e+01 2.73972603e-03 5.00000000e-01 8.33333333e-02]\n"," [1.79000000e+01 5.47945205e-03 6.66666667e-01 8.33333333e-02]\n"," [1.88000000e+01 8.21917808e-03 8.33333333e-01 8.33333333e-02]\n"," [1.46000000e+01 1.09589041e-02 1.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.36986301e-02 0.00000000e+00 8.33333333e-02]],  y[0]: 15.8\n","x[1]: [[1.79000000e+01 5.47945205e-03 6.66666667e-01 8.33333333e-02]\n"," [1.88000000e+01 8.21917808e-03 8.33333333e-01 8.33333333e-02]\n"," [1.46000000e+01 1.09589041e-02 1.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.36986301e-02 0.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.64383562e-02 1.66666667e-01 8.33333333e-02]],  y[1]: 17.4\n","x[2]: [[1.88000000e+01 8.21917808e-03 8.33333333e-01 8.33333333e-02]\n"," [1.46000000e+01 1.09589041e-02 1.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.36986301e-02 0.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.64383562e-02 1.66666667e-01 8.33333333e-02]\n"," [1.58000000e+01 1.91780822e-02 3.33333333e-01 8.33333333e-02]],  y[2]: 21.8\n","x[3]: [[1.46000000e+01 1.09589041e-02 1.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.36986301e-02 0.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.64383562e-02 1.66666667e-01 8.33333333e-02]\n"," [1.58000000e+01 1.91780822e-02 3.33333333e-01 8.33333333e-02]\n"," [1.74000000e+01 2.19178082e-02 5.00000000e-01 8.33333333e-02]],  y[3]: 20.0\n","x[4]: [[1.58000000e+01 1.36986301e-02 0.00000000e+00 8.33333333e-02]\n"," [1.58000000e+01 1.64383562e-02 1.66666667e-01 8.33333333e-02]\n"," [1.58000000e+01 1.91780822e-02 3.33333333e-01 8.33333333e-02]\n"," [1.74000000e+01 2.19178082e-02 5.00000000e-01 8.33333333e-02]\n"," [2.18000000e+01 2.46575342e-02 6.66666667e-01 8.33333333e-02]],  y[4]: 16.2\n","x[5]: [[1.58000000e+01 1.64383562e-02 1.66666667e-01 8.33333333e-02]\n"," [1.58000000e+01 1.91780822e-02 3.33333333e-01 8.33333333e-02]\n"," [1.74000000e+01 2.19178082e-02 5.00000000e-01 8.33333333e-02]\n"," [2.18000000e+01 2.46575342e-02 6.66666667e-01 8.33333333e-02]\n"," [2.00000000e+01 2.73972603e-02 8.33333333e-01 8.33333333e-02]],  y[5]: 13.3\n","x[6]: [[1.58000000e+01 1.91780822e-02 3.33333333e-01 8.33333333e-02]\n"," [1.74000000e+01 2.19178082e-02 5.00000000e-01 8.33333333e-02]\n"," [2.18000000e+01 2.46575342e-02 6.66666667e-01 8.33333333e-02]\n"," [2.00000000e+01 2.73972603e-02 8.33333333e-01 8.33333333e-02]\n"," [1.62000000e+01 3.01369863e-02 1.00000000e+00 8.33333333e-02]],  y[6]: 16.7\n","x[7]: [[17.4         0.02191781  0.5         0.08333333]\n"," [21.8         0.02465753  0.66666667  0.08333333]\n"," [20.          0.02739726  0.83333333  0.08333333]\n"," [16.2         0.03013699  1.          0.08333333]\n"," [13.3         0.03287671  0.          0.08333333]],  y[7]: 21.5\n","x[8]: [[21.8         0.02465753  0.66666667  0.08333333]\n"," [20.          0.02739726  0.83333333  0.08333333]\n"," [16.2         0.03013699  1.          0.08333333]\n"," [13.3         0.03287671  0.          0.08333333]\n"," [16.7         0.03561644  0.16666667  0.08333333]],  y[8]: 25.0\n","x[9]: [[20.          0.02739726  0.83333333  0.08333333]\n"," [16.2         0.03013699  1.          0.08333333]\n"," [13.3         0.03287671  0.          0.08333333]\n"," [16.7         0.03561644  0.16666667  0.08333333]\n"," [21.5         0.03835616  0.33333333  0.08333333]],  y[9]: 20.7\n"]}],"source":["## Create windows\n","X_train, y_train = create_windows_multivariate_np(train_data, past, future, 0)\n","X_test, y_test = create_windows_multivariate_np(test_data, past, future, 0)\n","\n","for i in range(10):\n","    print(f\"x[{i}]: {X_train[i]},  y[{i}]: {y_train[i]}\")"]},{"cell_type":"code","execution_count":106,"id":"stable-estate","metadata":{"id":"stable-estate"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_27\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">136,192</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ layer_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_16                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ layer_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">787,456</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m136,192\u001b[0m │\n","│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ layer_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_16                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │     \u001b[38;5;34m1,050,624\u001b[0m │\n","│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ layer_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m787,456\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,017,025</span> (7.69 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,017,025\u001b[0m (7.69 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,017,025</span> (7.69 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,017,025\u001b[0m (7.69 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.regularizers import L1L2\n","from tensorflow.keras.layers import LSTM, Bidirectional\n","\n","inputs = keras.layers.Input(shape=(5, 4))\n","\n","# First layer - Bidirectional LSTM with regularization\n","x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=L1L2(l1=1e-5, l2=1e-4)))(inputs)\n","x = keras.layers.Dropout(0.3)(x)\n","x = keras.layers.LayerNormalization()(x)\n","\n","# Second layer - Bidirectional LSTM\n","x = Bidirectional(LSTM(256, return_sequences=True, kernel_regularizer=L1L2(l1=1e-5, l2=1e-4)))(x)\n","x = keras.layers.Dropout(0.3)(x)\n","x = keras.layers.LayerNormalization()(x)\n","\n","# Third layer - LSTM\n","x = LSTM(256, return_sequences=False, kernel_regularizer=L1L2(l1=1e-5, l2=1e-4))(x)\n","x = keras.layers.Dropout(0.3)(x)\n","\n","# Dense layers before output\n","x = keras.layers.Dense(128, activation='relu')(x)\n","x = keras.layers.Dense(64, activation='relu')(x)\n","\n","# Output layer\n","outputs = keras.layers.Dense(1)(x)\n","\n","# Construcción y compilación del modelo\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","model.summary()"]},{"cell_type":"code","execution_count":107,"id":"structured-philip","metadata":{"id":"structured-philip"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - loss: 47.6111 - val_loss: 19.5566\n","Epoch 2/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 15.8605 - val_loss: 9.1060\n","Epoch 3/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 10.4735 - val_loss: 9.5430\n","Epoch 4/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 10.9162 - val_loss: 9.2550\n","Epoch 5/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 10.2181 - val_loss: 9.4593\n","Epoch 6/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 10.2771 - val_loss: 9.3648\n","Epoch 7/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 10.2485 - val_loss: 9.3177\n","Epoch 8/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 10.4227 - val_loss: 9.2458\n","Epoch 9/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 10.2367 - val_loss: 9.2180\n","Epoch 10/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 10.0708 - val_loss: 8.9809\n","Epoch 11/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.8689 - val_loss: 9.3108\n","Epoch 12/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 9.9253 - val_loss: 9.2014\n","Epoch 13/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 10.1048 - val_loss: 8.9015\n","Epoch 14/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 9.8954 - val_loss: 9.3740\n","Epoch 15/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 9.9554 - val_loss: 8.9495\n","Epoch 16/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 9.7864 - val_loss: 8.9945\n","Epoch 17/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 9.5507 - val_loss: 8.7325\n","Epoch 18/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 9.6666 - val_loss: 8.7586\n","Epoch 19/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 10.0594 - val_loss: 8.8907\n","Epoch 20/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.6614 - val_loss: 8.7895\n","Epoch 21/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.6380 - val_loss: 8.4572\n","Epoch 22/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.6929 - val_loss: 8.4727\n","Epoch 23/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.7507 - val_loss: 8.7077\n","Epoch 24/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.8915 - val_loss: 8.3412\n","Epoch 25/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 9.4342 - val_loss: 8.1660\n","Epoch 26/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.6076 - val_loss: 8.3105\n","Epoch 27/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.4938 - val_loss: 8.1727\n","Epoch 28/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.3893 - val_loss: 8.0798\n","Epoch 29/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 9.2045 - val_loss: 8.2032\n","Epoch 30/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.3193 - val_loss: 8.1475\n","Epoch 31/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.2267 - val_loss: 8.1710\n","Epoch 32/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 9.1715 - val_loss: 8.4947\n","Epoch 33/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 9.1928 - val_loss: 8.0983\n","Epoch 34/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 9.0320 - val_loss: 8.0139\n","Epoch 35/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 8.6676 - val_loss: 7.9947\n","Epoch 36/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 8.9221 - val_loss: 8.0015\n","Epoch 37/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.9273 - val_loss: 8.1481\n","Epoch 38/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 9.3197 - val_loss: 8.1232\n","Epoch 39/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.9949 - val_loss: 8.6534\n","Epoch 40/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 8.6997 - val_loss: 8.1104\n","Epoch 41/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 8.8501 - val_loss: 8.7300\n","Epoch 42/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 8.9333 - val_loss: 7.8026\n","Epoch 43/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.5331 - val_loss: 8.5059\n","Epoch 44/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 8.6108 - val_loss: 8.0515\n","Epoch 45/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - loss: 8.5706 - val_loss: 8.0640\n","Epoch 46/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 8.7382 - val_loss: 7.9667\n","Epoch 47/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.5474 - val_loss: 8.2269\n","Epoch 48/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 8.6827 - val_loss: 8.2128\n","Epoch 49/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.6087 - val_loss: 8.0898\n","Epoch 50/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 8.3098 - val_loss: 8.0800\n","Epoch 51/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - loss: 8.4092 - val_loss: 8.0613\n","Epoch 52/200\n","\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 8.5132 - val_loss: 8.4087\n"]}],"source":["es_callback = keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\", min_delta=0, patience=10)\n","\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=200,\n","    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",")"]},{"cell_type":"code","execution_count":108,"id":"assigned-afternoon","metadata":{"id":"assigned-afternoon"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0531\n","Test Loss: 6.513253211975098\n"]}],"source":["results = model.evaluate(X_test, y_test, verbose=1)\n","print('Test Loss: {}'.format(results))"]},{"cell_type":"markdown","id":"precise-tract","metadata":{"id":"precise-tract"},"source":["<a name='3.4'></a>\n","## Cuestión 4: ¿En cuáles de estas aplicaciones se usaría un arquitectura 'many-to-one'?\n","\n","**a)** Clasificación de sentimiento en textos\n","\n","**b)** Verificación de voz para iniciar el ordenador.\n","\n","**c)** Generación de música.\n","\n","**d)** Un clasificador que clasifique piezas de música según su autor.\n"]},{"cell_type":"markdown","id":"professional-mayor","metadata":{"id":"professional-mayor"},"source":["En una configuración \"many-to-one\", la red recibe una secuencia de entradas y produce una única salida al final de la secuencia. Este tipo de arquitectura es adecuada para tareas donde el contexto de la secuencia completa es necesario para producir una respuesta, como es el caso en:\n","\n","**a) Clasificación de sentimiento en textos:** Se analiza una secuencia de palabras (la entrada) para determinar si el sentimiento general del texto es positivo, negativo o neutro (una única salida). Por tanto, es una aplicación \"many-to-one\".\n","\n","**b) Verificación de voz para iniciar el ordenador:**  es \"many-to-one\" si se centra en clasificar la secuencia de audio como perteneciente a un usuario autorizado o no.\n","\n","**d) Un clasificador que clasifique piezas de música según su autor:** Aquí, la entrada es una secuencia de notas o sonidos, y la salida es la clasificación del autor de la pieza, que es una única salida basada en la secuencia completa. Por lo tanto, es una aplicación \"many-to-one\"."]},{"cell_type":"markdown","id":"fallen-error","metadata":{"id":"fallen-error"},"source":["<a name='3.5'></a>\n","## Cuestión 5: ¿Qué ventajas aporta el uso de word embeddings?\n","\n","**a)** Permiten reducir la dimensión de entrada respecto al one-hot encoding.\n","\n","**b)** Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.\n","\n","**c)** Son una manera de realizar transfer learning en nlp.\n","\n","**d)** Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA.\n"]},{"cell_type":"markdown","id":"stylish-polish","metadata":{"id":"stylish-polish"},"source":["Las respuestas correctas serían todas las opciones:\n","\n","**a) Permiten reducir la dimensión de entrada respecto al one-hot encoding.**  \n","Los word embeddings representan palabras en un espacio de características continuo y de menor dimensión en comparación con el one-hot encoding, donde la dimensión del vector es igual al tamaño del vocabulario. Esto reduce drásticamente la dimensión de los datos de entrada sin perder información sobre la palabra.\n","\n","**b) Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.**  \n","En el espacio vectorial de los embeddings, palabras con significados similares o que se utilizan en contextos similares tienden a estar más cerca unas de otras, lo que permite capturar y utilizar la similaridad semántica de manera efectiva. En contraste, el one-hot encoding trata todas las palabras como igualmente distintas entre sí sin ninguna noción de similaridad.\n","\n","**c) Son una manera de realizar transfer learning en NLP.**  \n","Los word embeddings pueden entrenarse en grandes conjuntos de datos y luego utilizarse en modelos más pequeños o tareas específicas, transfiriendo así el conocimiento aprendido sobre el lenguaje de un dominio a otro. Esto es especialmente útil en situaciones donde los datos de entrenamiento son limitados.\n","\n","**d) Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensiones como el PCA.**  \n","Dado que los word embeddings representan palabras en un espacio de características de alta dimensión, técnicas de reducción de dimensiones como el Análisis de Componentes Principales (PCA) o t-SNE pueden utilizarse para proyectar estos espacios a dos o tres dimensiones. Esto hace posible visualizar la relación entre palabras, mostrando cómo ciertas palabras están agrupadas o relacionadas entre sí en el espacio reducido.\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false}},"nbformat":4,"nbformat_minor":5}
